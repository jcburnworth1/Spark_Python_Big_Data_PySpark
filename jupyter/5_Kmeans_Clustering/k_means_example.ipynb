{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ed34b5-5537-4f6e-84f4-853b5d88034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "## Set seed\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539349b9-0e8a-4007-a84c-728bf73c1fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Spark Session\n",
    "spark = SparkSession.builder.appName('kmExample').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0281801b-0443-4a44-87a7-eb213fe574e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/07 03:33:16 WARN org.apache.spark.ml.source.libsvm.LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n",
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|           (3,[],[])|\n",
      "|  1.0|(3,[0,1,2],[0.1,0...|\n",
      "|  2.0|(3,[0,1,2],[0.2,0...|\n",
      "|  3.0|(3,[0,1,2],[9.0,9...|\n",
      "|  4.0|(3,[0,1,2],[9.1,9...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Load Data\n",
    "df = spark.read.format('libsvm').load('gs://spark-training-data/datasets/sample_kmeans_data.txt')\n",
    "df.show(5)\n",
    "df.printSchema() ## Confirm proper schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32566bf5-8736-461f-bdfb-71affe6f1e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|           (3,[],[])|\n",
      "|(3,[0,1,2],[0.1,0...|\n",
      "|(3,[0,1,2],[0.2,0...|\n",
      "|(3,[0,1,2],[9.0,9...|\n",
      "|(3,[0,1,2],[9.1,9...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Setup Final Data\n",
    "final_data = df.select(['features'])\n",
    "final_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3be5665d-9a90-476f-b42c-07bfede93ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup Model\n",
    "kmeans = KMeans(featuresCol='features').setK(3).setSeed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68f75696-25d8-41cb-9be0-78e8c869801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit Model\n",
    "kmeans_model = kmeans.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c17a9f21-69c5-404a-935c-478da4633fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07499999999994544"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Evaluate KMeans Model\n",
    "wssse = kmeans_model.summary.trainingCost\n",
    "wssse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fccc6fad-f222-4567-a5f5-c14377a6db7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([9.1, 9.1, 9.1]), array([0.05, 0.05, 0.05]), array([0.2, 0.2, 0.2])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get Centers\n",
    "centers = kmeans_model.clusterCenters()\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "523b17cf-2908-46cb-a91f-c78ddcd4e03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            features|prediction|\n",
      "+--------------------+----------+\n",
      "|           (3,[],[])|         1|\n",
      "|(3,[0,1,2],[0.1,0...|         1|\n",
      "|(3,[0,1,2],[0.2,0...|         2|\n",
      "|(3,[0,1,2],[9.0,9...|         0|\n",
      "|(3,[0,1,2],[9.1,9...|         0|\n",
      "|(3,[0,1,2],[9.2,9...|         0|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Make Predictions & Show Clusters\n",
    "predictions_df = kmeans_model.transform(final_data)\n",
    "predictions_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}